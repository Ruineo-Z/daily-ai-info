"""Daily AI Info - ä¸»ç¨‹åºå…¥å£"""

import asyncio
from datetime import datetime
from app.logger_config import setup_logger
from app.config import validate_config
from app.crawlers.github_trending_web import GitHubTrendingWebCrawler
from app.ai_processor import AIProcessor
from loguru import logger


def generate_report_path():
    """ç”ŸæˆæŒ‰æ—¥æœŸç»„ç»‡çš„GitHub Trendingåˆ†ææŠ¥å‘Šè·¯å¾„"""
    import os

    today = datetime.now()
    year = today.strftime("%Y")           # 2025
    month = today.strftime("%m")          # 09
    day = today.strftime("%d")            # 16
    time_str = today.strftime("%H%M")     # 2323

    # æŒ‰æ—¥æœŸç»„ç»‡ç›®å½•ç»“æ„: data/2025/09/16/
    date_dir = os.path.join("data", year, month, day)

    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs(date_dir, exist_ok=True)

    # æ–‡ä»¶å: GitHub-Trending-AIåˆ†æ_HHMM.md
    filename = f"GitHub-Trending-AIåˆ†æ_{time_str}.md"
    filepath = os.path.join(date_dir, filename)

    return filename, filepath, date_dir


def generate_markdown_report(summary_result: dict, projects: list) -> str:
    """ç”ŸæˆGitHub Trending AIæŠ€æœ¯åˆ†ææŠ¥å‘Š"""
    today = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")

    markdown = f"""# GitHub Trending AIæŠ€æœ¯åˆ†ææŠ¥å‘Š - {today}

> åŸºäºGitHub Daily Trendingçš„AIæŠ€æœ¯åŠ¨æ€æ·±åº¦åˆ†æ

## ğŸ“‹ ä»Šæ—¥æ‘˜è¦

{summary_result.get('summary', 'ä»Šæ—¥AIæŠ€æœ¯èµ„è®¯å·²æ•´ç†å®Œæˆ')}

"""

    # æŠ€æœ¯è¶‹åŠ¿
    trends = summary_result.get('trends', [])
    if trends:
        markdown += "## ğŸ“ˆ æ ¸å¿ƒæŠ€æœ¯è¶‹åŠ¿\n\n"
        for i, trend in enumerate(trends, 1):
            markdown += f"{i}. {trend}\n"
        markdown += "\n"

    # é¡¹ç›®è¯¦æƒ…
    markdown += f"## ğŸš€ GitHubçƒ­é—¨é¡¹ç›®æ·±åº¦è§£æ ({len(projects)}ä¸ª)\n\n"
    project_summaries = summary_result.get('project_summaries', [])

    for i, project in enumerate(projects, 1):
        name = project.get('name', 'Unknown')
        description = project.get('description', 'æš‚æ— æè¿°')
        url = project.get('url', '#')
        stars = project.get('stars', '0')
        language = project.get('language', 'Unknown')
        stars_today = project.get('stars_today', '')
        author = project.get('author', 'Unknown')

        markdown += f"### {i}. [{name}]({url})\n\n"

        # AIç”Ÿæˆçš„æŠ€æœ¯æ´å¯Ÿ
        if i <= len(project_summaries) and project_summaries[i-1]:
            ai_summary = project_summaries[i-1].strip()
            # æ¸…ç†å‰ç¼€
            prefixes = [f"{i}.", f"{i}ã€", "- ", "* ", f"**{name}**: ", f"**{name.split('/')[-1]}**: "]
            for prefix in prefixes:
                if ai_summary.startswith(prefix):
                    ai_summary = ai_summary[len(prefix):].strip()
                    break
            markdown += f"**AIæŠ€æœ¯æ´å¯Ÿ**: {ai_summary}\n\n"
        else:
            markdown += f"**é¡¹ç›®ç®€ä»‹**: {description}\n\n"

        markdown += f"**GitHubæ•°æ®**:\n"
        markdown += f"- â­ **Stars**: {stars}"
        if stars_today:
            markdown += f" (ä»Šæ—¥+{stars_today})"
        markdown += f"\n- ğŸ’» **ä¸»è¯­è¨€**: {language}\n"
        markdown += f"- ğŸ‘¨â€ğŸ’» **ä½œè€…**: {author}\n\n"
        markdown += "---\n\n"

    # ç»Ÿè®¡åˆ†æ
    markdown += "## ğŸ“Š GitHub Trendingæ•°æ®åˆ†æ\n\n"
    markdown += f"- **åˆ†æé¡¹ç›®æ€»æ•°**: {len(projects)}\n"

    # ç¼–ç¨‹è¯­è¨€åˆ†æ
    languages = {}
    for project in projects:
        lang = project.get('language', 'Unknown')
        languages[lang] = languages.get(lang, 0) + 1

    top_languages = sorted(languages.items(), key=lambda x: x[1], reverse=True)[:7]
    markdown += f"- **ç¼–ç¨‹è¯­è¨€åˆ†å¸ƒ**: {', '.join([f'{lang}({count})' for lang, count in top_languages])}\n"

    # Starsæ´»è·ƒåº¦åˆ†æ
    total_stars_today = 0
    for project in projects:
        stars_today_str = project.get('stars_today', '').replace(' stars today', '').replace(',', '')
        if stars_today_str.isdigit():
            total_stars_today += int(stars_today_str)

    if total_stars_today > 0:
        markdown += f"- **ä»Šæ—¥æ–°å¢Starsæ€»æ•°**: {total_stars_today:,}\n"

    # æŠ¥å‘Šä¿¡æ¯
    markdown += f"\n## ğŸ“‹ åˆ†ææŠ¥å‘Šä¿¡æ¯\n\n"
    markdown += f"- **æ•°æ®æ¥æº**: GitHub Trending (Daily)\n"
    markdown += f"- **åˆ†ææ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
    markdown += f"- **AIåˆ†æå¼•æ“**: Google Gemini 2.5 Pro\n"
    markdown += f"- **åˆ†ææ·±åº¦**: é¡¹ç›®æè¿° + READMEå†…å®¹\n"
    markdown += f"- **æŠ¥å‘Šæ ¼å¼**: Markdown v1.0\n"

    return markdown


async def main():
    """ä¸»ç¨‹åº - GitHub Trending AIæŠ€æœ¯åˆ†æ"""
    # åˆå§‹åŒ–æ—¥å¿—
    setup_logger()
    logger.info("=== GitHub Trending AIæŠ€æœ¯åˆ†æç¨‹åºå¯åŠ¨ ===")

    # éªŒè¯é…ç½®
    if not validate_config():
        logger.error("é…ç½®éªŒè¯å¤±è´¥ï¼Œç¨‹åºé€€å‡º")
        return

    try:
        # æ­¥éª¤1: çˆ¬å–GitHub Trendingæ•°æ®
        logger.info("ğŸ” å¼€å§‹çˆ¬å–GitHub Trendingæ•°æ®")
        async with GitHubTrendingWebCrawler() as crawler:
            trending_data = await crawler.crawl(fetch_readme=True)

        if not trending_data:
            logger.error("æœªè·å–åˆ°trendingæ•°æ®ï¼Œç¨‹åºé€€å‡º")
            return

        logger.info(f"âœ… çˆ¬å–å®Œæˆï¼Œè·å¾— {len(trending_data)} ä¸ªçƒ­é—¨é¡¹ç›®")

        # æ­¥éª¤2: AIå¤„ç†ä¸åˆ†æ
        logger.info("ğŸ¤– å¯åŠ¨AIåˆ†æå¼•æ“")
        ai_processor = AIProcessor()

        logger.info("ğŸ§¹ æ‰§è¡Œæ™ºèƒ½å»é‡")
        deduplicated_data = await ai_processor.deduplicate_by_titles(trending_data)

        logger.info("ğŸ“ ç”ŸæˆæŠ€æœ¯æ´å¯Ÿä¸è¶‹åŠ¿åˆ†æ")
        summary_result = await ai_processor.summarize_content(deduplicated_data)

        # æ­¥éª¤3: ç”Ÿæˆä¸“ä¸šæŠ¥å‘Š
        logger.info("ğŸ“‹ ç”ŸæˆGitHub Trending AIæŠ€æœ¯åˆ†ææŠ¥å‘Š")
        markdown_content = generate_markdown_report(summary_result, deduplicated_data)

        # ä¿å­˜æŠ¥å‘Š - æŒ‰æ—¥æœŸç»„ç»‡ç›®å½•
        filename, filepath, date_dir = generate_report_path()
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(markdown_content)

        # è¾“å‡ºç»“æœç»Ÿè®¡
        trends_count = len(summary_result.get('trends', []))
        logger.info(f"ğŸ‰ åˆ†æå®Œæˆï¼")
        logger.info(f"ğŸ“Š å¤„ç†ç»Ÿè®¡:")
        logger.info(f"   - åˆ†æé¡¹ç›®: {len(deduplicated_data)} ä¸ª")
        logger.info(f"   - æŠ€æœ¯è¶‹åŠ¿: {trends_count} ä¸ª")
        logger.info(f"   - æŠ¥å‘Šç›®å½•: {date_dir}")
        logger.info(f"   - æŠ¥å‘Šæ–‡ä»¶: {filename}")
        logger.info(f"   - å®Œæ•´è·¯å¾„: {filepath}")
        logger.info(f"   - æ–‡ä»¶å¤§å°: {len(markdown_content):,} å­—ç¬¦")

        logger.info("âœ… GitHub Trending AIæŠ€æœ¯åˆ†æç¨‹åºæ‰§è¡Œå®Œæˆ")

    except Exception as e:
        logger.error(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        raise


if __name__ == "__main__":
    asyncio.run(main())